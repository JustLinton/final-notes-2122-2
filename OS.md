 

### 导言

#### 操作系统的四个特征

- 并发
  - 两个或多个事件`同时发生`，确切的说是同`一段时间`内,而非一个时刻。如果真的同一时刻同时发生，那叫`并行`。
- 共享
  - 共享即资源在进程间的共享，分为互斥共享和同时访问共享。前者用于临界资源。
  - 共享为并发提供了条件。如果资源不能被两个进程共同访问，那么他们也就不可能互斥执行。
- 虚拟
  - 把物理的实体变成逻辑上的实体，并能赋予其新的特征。例如虚存、Spooling等。
- 异步
  - 因为对进城来说，资源并不总是充足的，所以进程是走走停停的，也就是他推进的速度是无法预知的。这种无法预知的推进速度即异步。
  - OS需要保证就算这些进程是异步推进的，其执行结果也应当符合预期。（即多次执行，结果一致）

#### 操作系统的作用

- 操作系统是工人，它操作计算机这个机器。用户是雇主。
- 操作系统操作机器，即对**处理器，存储器、设备、文件**四大部分进行**管理**；
- 雇主要给工人传递命令，工人要反馈，即操作系统要对用户预留**接口**。
  - 这种接口分为程序接口和命令接口。前者是例如系统调用API；后者是用户界面。
  - 命令接口分为联机接口和脱机接口。前者是交互式的，例如shell；后者是批处理的，例如slurm。
- 有了工人，机器才能发挥出更大作用，所以操作系统可以**扩充计算机系统**。
  - 扩充计算机系统，是相对于计算机裸机（没有软件覆盖的计算机系统）而言的。
  - 有了OS，裸机才能发挥**应有的功能**。

#### 批处理系统

- 为了解决IO速度和CPU之间的**速度差异**。
- 批处理分为单道批处理和多道批处理。后者是在宏观上并行，在微观上串行。

#### 分时系统

- 为了解决用户不能**交互**的问题。
- 把CPU时间划分成时间片，每个时间片给一个用户，这样轮流使用。如果某作业不能在这个时间片内完成，就进入等待，等待下一次其得到时间片。因为时间片较短，所以用户感觉好像自己独占了计算机。
- 分时系统是交互式系统，通过多个终端连接到中心计算机上实现。其交互性是和批处理系统的最大区别。
- **现在的OS例如Windows可以理解为分时系统，而分时的对象不再是用户，而是一个个进程。**

#### 实时系统

- 分时系统虽然在宏观上是交互的，但是在微观上其还是会有一定的延迟。这对于诸如导弹发射这样的精确任务不能胜任。
- 实时系统的特点是：必须在完全正确的时间点给出响应（如导弹制导），或必须在一定时间限制内给出响应（如订票系统）。前者称为**硬实时**，后者称为**软实时**。
- 常使用**抢占式的优先级高者优先**调度算法。
- 实时系统的目标是响应速度。为此它**可以放弃**一定的资源利用率。**因此实时系统资源利用率一般比较低。**

#### 网络操作系统、分布式操作系统

- 网络操作系统
  - 计算机之间可以通信和资源共享。但是**不能协作**完成工作。
- 分布式操作系统具有分布性、并行性。
  - 计算机之间没有主从关系。计算机之间可以通信和资源共享。
  - 分布性：任何工作可以分布在若干计算机上，协同完成任务。

#### 核心态、用户态及其切换（注意上下文的保存和恢复）

- 可以执行特权指令的状态是核心态。可以理解为CPU有一小开关，控制着当前是否处于核心态。
  - 常见特权指令：IO指令
- **内核运行在核心态，用户程序运行在用户态。**
- 从用户态转为核心态的过程称为“陷入”。“陷入”是硬件过程，即**只要**发生了中断，**硬件**就会把核心态标志位置1.
- 核心态、用户态切换的过程需要保护现场（CPU寄存器）。这和进程切换类似。因为当进程从用户态转到核心态，实际上就不是跑这个进程的程序了，而是执行内核程序，所以需要保存、恢复现场（就像进程切换那样）。

#### 内核

- 内核是操作系统最底层的软件，是计算机功能的延伸。
- 内核包括以下四部分内容：
  - 时钟管理
    - 系统维护一个时钟
    - 时钟可以为用户提供标准时间
    - 时钟是分时系统的关键。当进程的时间片用完，它就从执行态转为就绪态。
  - 中断机制
    - 中断发明的初衷是提升CPU的利用率（例如进行IO时，你数据传完了再提出中断去高速CPU，则实现了IO设备与CPU的并行。）
    - **在中断中，内核负责保护现场（仅保存程序状态字，因为PC是隐指令负责的）和恢复现场、转到中断处理程序。**
  - 原语
    - 是操作系统最**接近硬件**的“小程序”，他们具有**原子性**，并且常常会被**频繁调用**。
    - **原子性通过进入程序时关中断，离开程序时开中断实现。**（只要关闭了中断，就不会被抢占。因为所谓时间片用尽、抢占，这些都是基于中断实现的。）
  - 系统控制的数据结构及处理
    - 数据结构就是用于OS正常运行的状态信息，包括PCB、FCB、Page Table等。

#### 外中断和内中断

- 外中断又称中断，是和当前CPU执行的程序**没有关系**的中断，例如键盘中断、打印机、时钟中断。它的中断处理程序往往**不**需要上下文信息。
- 内中断又称异常、陷阱。内中断不能被屏蔽，一旦出现必须处理；它的中断处理程序**需要上下文信息**。
  - 例：软件出错、硬件出错、**访管中断**（又称**自愿中断**，是指调用访管指令（访管指令**只能由用户态下执行**，用于主动切换核心态，所以它**不是特权指令**））、用户程序错误地**尝试使用特权指令**（此时产生中断来防止其使用）等。
- **无论是内中断还是外中断，只要发生中断，CPU就从用户态陷入核心态。**从用户态转为核心态的过程称为“陷入”。“陷入”是硬件过程，即只要发生了中断，**硬件**就会把核心态标志位置1.

#### 系统调用

- 在用户态下执行陷阱指令，就陷入核心态，此时CPU由内核接管，在核心态执行，提供相应功能。执行完毕后，再返回用户态，从而返回用户程序。
- **在编写C程序时，通过API调用系统调用函数，这些函数会被编译成陷阱指令和若干相关参数。**

#### 微内核

- 微内核是更具模块化思想的内核设计，把一些不需要在核心态运行的系统程序分离出去，让他们在用户态运行（因为根据定义，内核是运行在核心态的，其他任何程序都在用户态。），然后他们之间的通信要通过内核实现（也就是每次互相通信都要陷入核心），这虽然使内核设计更加简单且更易于扩展，但是效率非常低（因为需要频换切换核心态）。
- 宏内核是把上述那些模块都集成在内核内，他们之间可以直接通信。缺点是过于庞大，不易于扩展与维护。

### 进程和线程

#### 进程

- 进程是一个程序在其数据集合上运行的过程，是系统进行资源分配的基本单位。
  - 这里的资源即CPU时间、内存、其他设备和服务。

#### PCB

- PCB是进程存在的唯一标志

#### 进程实体（进程映像）

- 由程序段、数据段、PCB构成。

#### 进程的五状态

- 创建态
  - 在这个过程中，PCB被创建，资源被分配。于是，进程实体就产生了。
  - 然后就可以进入就绪态。
- 结束态
  - 进行资源释放和回收。
- 对比：阻塞态和就绪态
  - 阻塞是进程进入了等待，等待一个时间的的发生。在这段时间内，**其不可能占用CPU，因为当前它因为`除了CPU外`的原因无法执行。**
  - 和就绪态的区别：就绪态等待的原因只是CPU时间，而阻塞态必然还在等待别的事情。**所以两者的区别是：`是否单纯因为`CPU时间而无法执行。**
  - 进程处在阻塞态的时间往往较长，比就绪态长得多。因为CPU时间片是很短的，这就导致进程会**频繁而短促**地在就绪态和执行态之间转换。而处在阻塞态的程序往往等待很长时间（相比CPU时间片来说），例如访问磁盘。

#### 常见的状态转换

- 执行-就绪
  - 可能是时间片用完了
  - 可能是被更高优先级进程抢占了
- 执行-阻塞
  - 这是一个主动行为（主动睡眠）。程序突然需要进行IO了，就等待IO的完成。
- 阻塞-就绪
  - 这是一个被动行为（被动唤醒）。当刚才那个程序的IO完成，它被服务程序**唤醒**了。

#### 进程管理原语

- 创建、终止、阻塞、唤醒、切换这五种操作实际上由OS提供的对应5种原语完成。这些都是原子操作。通过关中断实现。

#### 进程的创建

- 一个进程可以创建另一个进程。称为父、子进程。子进程在没有exec之前，直接继承（copy）父进程的资源的内容。子进程如果退出，由父进程负责释放资源、传递返回值等。
- 原语
  - 分配PID，并创建新PCB
  - 分配资源。如果资源不足，则进入等待
  - 初始化PCB，例如设定优先级
  - 放入就绪队列

#### 进程的终止

- 进程可以正常终止，可以出现异常而结束，可以由外界信号结束（例如SIGINT）

#### 进程的阻塞和唤醒

- 阻塞原语（进程主动调用）
  - 找到PCB，保护现场，停止运行，把他插入相应资源的等待队列
- 唤醒原语（其他进程调用，本进程被动唤醒）
  - 从这种资源的等待队列找到PCB，放入就绪队列

#### 进程的切换（注意上下文的保存和恢复）

- 原语
  - 中止执行，保存上下文（各寄存器）
  - 更新当前进程PCB，并把他移动到相应队列（就绪队列或等待队列）
  - 从就绪队列选择一个新的PCB，更新其PCB
  - 恢复上下文（各寄存器），开始执行

#### PCB的结构

- PCB是哆啦A梦的口袋，任何关于该进程的信息都从这里找。
- 进程描述信息（**负责进程的标识**）
  - 包括UID、PID
- 进程控制和管理信息（**负责进程的执行**）
  - 进程状态（五态之一）
  - 优先级
  - 内存中的代码入口、外存中的代码入口
- 审计信息（**负责进程的审计**）
  - CPU、内存等资源占用时间
- 资源清单（**负责进程的资源**）
  - 各内存段指针（**堆栈段**，代码段，数据段）
  - 进程FCB
  - 外设
- CPU上下文（**负责进程的切换**）
  - 各寄存器的数值，各标志位的数值（即DOS里面-t出来的那些）

#### PCB的组织

- 系统中有就绪队列，有各种资源分别的阻塞队列。这些队列里面是PCB进行排列。
- 索引方式（数组）
  - 队列里的成员实际上是用了PCB的索引代替。而真正的PCB是集中存放的。
- 链接方式（链表）
  - 队列是链表，元素是PCB。

#### 进程之间的存储共享

- 共享存储
  - 分为基于数据结构的共享和直接基于存储空间的共享。这段空间由系统调用进行安排。
  - 属于临界资源，需要互斥访问。
  - **对于一个进程，其各线程之间是天生满足“共享存储”概念的。**
- 消息传递
  - 如果只需要进行信号的传递，可以**不必大费周章**去申请共享内存并管理他。只需要使用OS提供的消息传递系统调用。
  - 直接消息传递（消息队列法）
    - A向B发送消息，则把消息挂在B的消息队列里面即可。
  - 间接消息传递（信箱法）
    - A向B发消息，则A发到B的信箱，B从信箱取。
- 管道
  - 管道实际上是一个共享文件，连接了两个进程。
  - 管道虽然是文件，但是它限制了最大体积，即它不能无限增大。这可以类比一个有限缓冲区。
  - 管道的两端可以看做是读者-写者。当管道文件满，写者如果还要write就阻塞；当管道文件空，读者如果还要read就阻塞。
  - 管道中的数据一旦读出就被删除。
  - 管道是半双工的，即同一时刻只能由一方作为写（读）者（就算你不close）。如果要实现全双工则需要两条管道。

#### 堆段、栈段、数据段、BSS段的区别

| 段     | 对应C语言变量                  | 解释                                                         |
| ------ | ------------------------------ | ------------------------------------------------------------ |
| 栈段   | 局部变量、函数参数、函数返回值 | 栈的LIFO的特性非常有利于像子过程调用这样的应用场景。当进入了一个局部空间，它一定还会再退出来，所以可以用栈。 |
| 堆段   | 动态分配内存变量(new,malloc)   | 可以联想DBMS里面的堆文件。                                   |
| 数据段 | 全局变量、静态变量、**常量**   | 是为整个程序所用的，所以保存在整体空间中                     |
| BSS段  | 未初始化的全局变量             | -                                                            |

#### 线程

- 线程是能表示一个执行中的程序的最小的单元。因此它只包含**CPU寄存器数据和堆栈段指针**（即程序执行的上下文）。
  - 堆栈段是这个程序中局部过程需要的执行资源。没有堆栈段就没有局部的概念。你没法拥有自己的变量。
  - 可以说，堆栈段就是一个“现场”。如果只有数据段，你就算不运行这个程序，他也是存在的。但是堆栈段给出了运行这个程序的动态。不同的线程在各自的运行状态中，他们的堆栈段是不一样的，但是他们都共享完全一样的那个数据段。
  - 所有线程都可以访问进程的数据段，因此大家可以通过静态变量或全局变量通信。
- 同一进程中，线程可以创建和撤销其他线程。**因此这些线程没有主次之分。**
- 同一进程中，所有线程共享这个进程占有的资源。
- CPU的时间调度以线程为单位。如果某次上下文切换发生在统一进程的不同线程之间，则这个切换时间可以忽略不计。
- 好处：
  - 可以看出，线程的TCB（线程控制块）只包含CPU寄存器和堆栈段信息，所以其切换、创建都非常迅速，不需要像进程那样把哆啦A梦的口袋的物件都安排个遍。
  - 便于通信。因为天然地就共用内存空间，相当于共享内存的通信方式已经安排好了。（可以直接通过读写全局变量的方式。）
  - 如果需要创建多个功能一致的进程，显然不如创建这些线程。
  - 在多CPU下，如果这个进程的不同线程在不同的CPU上运行，就可以提升速度。
  - **提升了系统的并发度：**因为上下文切换开销平均来看变小了，则效率变高了，在一定的时间间隔内能运行更多线程。

#### 用户级线程和内核级线程

- 区别与联系
  - 内核为该进程分配内核级线程。取决于采用的映射模型，会分配一个或多个。内核级线程是**真正占用系统资源的线程实体**。
  - 用户级线程是线程库的一种数据结构。用于描述一个**逻辑上的线程**。
  - 可以理解为：用户级线程是内核级线程执行状态（上下文）的一个镜像。该镜像是用户级线程离开内核级线程时那一瞬间的上下文。当该用户级线程再次被映射到内核级线程上，该镜像用于恢复上次离开时的上下文。
- 用户级线程是线程库提供的结构，其管理、**调度**都**由用户级线程库完成**，**与内核没有半毛钱关系**。属于自娱自乐型。如果进程只被分配了一个内核级线程（即采用多对一映射），那么就算在用户空间是多线程，这个进程仍然作为一个整体被调度。在这个进程内，不同线程之间的调度由线程库自行完成，而不是OS。

> - **用户级线程必须被映射到内核级线程上才能执行**（因为线程库不能执行这个线程，只能通过OS去执行这个线程。**线程库只能维护这个线程的上下文，从而便于把上下文映射给内核去执行**）。**因此线程库要做的工作就是选择要把哪个用户级线程映射上去。**
> - 所以，用户级线程只是线程库的一个调度单位，只是一个数据结构，用于保存这个线程的上下文信息。它并不是OS里面的一个真正的线程，而只是一个**逻辑上的**线程。所以用户级线程可以有无数个，但是OS因为性能的原因只能有有限个内核级线程。
> - 可以预见，用户级线程的切换不需要陷入核心态。但是内核级线程的切换是真正的线程切换，需要进入核心态。

- 并不是说自娱自乐（多对一模型）就没有意义。因为这个时候线程库相当于一个小的OS，待映射的那个内核级线程相当于一个CPU，线程库完成了这个进程范围内的线程调度。（同时，这个进程还会作为一个整体被OS调度。因为在多对一模型下，这个进程只有一个线程。）
  - 也就是说，形成了两级调度。
- 为什么说内核看不见用户级线程？**因为用户线程只是线程库里面的一种数据结构，和内核没有半毛钱关系。**

> 用户级线程是代码**逻辑**，内核级线程是线程**实体**。

#### 多对一模型

- 这是线程调度完全交给线程库的模型。在操作系统看来，用户并没有使用OS提供的多线程功能。

> **因为真正的线程是内核线程，内核线程才是OS进行调度的基本单位**，所以每个用户线程只是线程库范围内进行调度的单位，与OS的调度无关。

- 因为实际上只有一个内核线程，所以一旦这个进程中的某个用户线程调用了引起阻塞的系统调用，就引起进程阻塞，这个进程的所有线程相当于是阻塞了（因为整个进程阻塞了）
- 而且这种模型不可能在多CPU环境下，不同用户线程在不同CPU上并行执行。因为它实际上只有一个内核线程，也就是只能被调度给一个CPU。

#### 一对一模型

> **因为真正的线程是内核线程，内核线程才是OS进行调度的基本单位**，因为每个用户线程真的就是内核线程了，所以他们都是OS进行调度的单位了。好耶。

- 好处：各线程可实现多CPU下的并行执行。且任意一个阻塞了不影响其他的。
- 缺点：影响性能（需要切换内核态实现调度）。

#### 多对多模型

是上述两种方法的折中。

#### 现代处理器的核心数、线程数、超线程（HT）技术

- 一个核心就是一个CPU。但是现代操作系统都以线程为调度的单位了，所以线程数量才是其并行能力的关键。
- 一般情况下，一个核心对应一个线程，这是正常情况。因为线程就算代替进程称为调度的基本单位，它也是需要核心去执行的。
- Intel发明超线程技术，只复制核心内供线程执行的必要部件，从而可以让一个核心支持多个线程并行执行。
- 于是，在HT的技术下，就有诸如“8核心16线程、64核心128线程”这样的CPU出来了。在以线程为调度的OS下，OS对核心线程的调度就是做出“让哪个核心线程去占用CPU的线程（**逻辑核心**）”的决定。**线程看起来更像是一个个的==逻辑核心==**。使用HT技术，能让逻辑核心数进一步**翻倍**。

#### 三种调度

- 长程调度：选择作业以创建进程
  - 往slurm上提交作业，则这些作业都在外存上等着。此时需要这种调度方法，把外存中的某个适合的作业以进程创建的方式使其进入内存，获得竞争CPU（核心或线程）的权利。
  - 频率低。例如我的模型要pending好几十分钟。
- 中程调度：选择进程以挂起
  - “挂起”由此而来。
  - 如果某进程**阻塞或==就绪==了**（即暂时不能运行），则把他的镜像放到外存，从而可以把它从内存清退到外存。当需要唤醒它时，再把它调回主存，进入就绪态。
  - 所以，挂起态是更加深度的阻塞或==就绪==态。因为它不仅不占用CPU，**还不占用内存了**。这样能提高内存的利用率。
- 短程调度：选择进程以执行
  - 从就绪队列选择一个执行。
  - 显然频率非常高，可能每过一个时间片的长度就要调度一下。
- 作业调度是前提，没有作业调度就没有进程；进程调度是归宿，最后都需要进程调度才能获得核心或线程；中级调度是优化方法，在阻塞态和就绪态都可能发生。

#### 进程的调度和进程的切换

- 切换往往在调度完成后紧接着立即进行。需要保存上一进程的上下文，恢复被调度过来的进程的上下文。内核中为每个进程都分配了一个栈，具体方式是把上一进程上下文入上一进程的内核栈，下一进程的上下文从下一进程的内核栈中弹出。
- 如果当前正在进行中断处理、**正在访问临界区**、或正在进行原子操作，是不允许进行调度的。因为调度是通过中断完成的（例如时间片耗尽产生中断信号，引发调度），而中断处理、原子操作都是关中断的。

> <u>**因为当且仅当出现了中断，才会进行进程调度和切换。**</u>

#### 剥夺调度和非剥夺调度（又称抢占式和非抢占式调度）

- ~~如果设置了请求调度位，在中断处理结束或系统调用结束后返回现场前，即可立即进行进程的调度切换，那么这就是**剥夺式调度**。~~
- 如果对于一个进程，直到其**阻塞了**才去调度新的进程来执行。
  - 注意，如果存在“时间片用尽”这种情况，则属于**剥夺**了。

#### 调度算法

- FCFS
  - 是非抢占算法，所以直到阻塞才能进行调度
  - 长作业优先：如果长作业来了，其他短作业要等好久
  - 利于CPU型作业，不利于IO型作业：如果频繁IO，则每次都要再排回队首等好久
  - 是其他调度算法的基础
- SJF（短作业优先）：选择最短的作业进行调度
  - 是非抢占算法，所以直到阻塞才能进行调度
  - **是平均等待时间、平均周转时间最短的调度算法。**
  - 长作业产生饥饿现象
  - 作业长度不好估计
- 优先级调度：选择`优先级`最高的作业进行调度
  - 有抢占、非抢占可选。如果抢占，那么只要来了个优先级更高的就让出核心或线程，否则还是等到阻塞才能进行调度
  - 优先级可以是动态的：例如随着时间的增加
  - **一般情况下，IO型进程优先级应当大于CPU型的。**
- 高响应比调度：选择`响应比`最高的作业进行调度
  - 响应比综合考虑了等待时间和作业长度，是对`SJF`和`动态优先级`的折中。分母是SJF，分子是动态优先级。
  - 短作业优先：在等待时间一定时，作业越短，响应比越大
  - 长作业不饥饿：就算作业较长，也可以通过等待达到相对有竞争力的响应比
- Round-Robin：带时间片剥夺的`SJF`算法
  - 采用SJF方式，但是加入了时间片剥夺。任务一旦被剥夺，就因为来的比较晚而排到就绪队列尾部。
  - 时间片过长会导致退化成SJF算法，时间片过短会导致上下文切换开销过大。
- n级反馈队列调度：
  - 算法
    - 系统中有$n$个队列。
    - 对于第 $i+1$和第 $i(i>=1,i<=n-1)$ 个队列，第 $i+1$ 比第 $i$个的时间片长1倍。
    - 第 $i$个队列开始执行当且仅当前面的 $1，2，3，...,i-1$各队列都是空。但是这是`抢占式`的：如果此时又有新作业来了，则这第 $i$个队列立即停止运行，转而去服务第1个队列的新来的进程。
    - 第 $1，2，3，...，n-1$个队列采用FCFS调度，第 $n$个队列采用RR调度。
    - 新来的作业总是加入第1个队列中，当它用完该队列对应的时间片，会进入下一级（这里是第2个队列）中，以此类推，直到第$n$级队列，则开始RR。
    - 如果一个作业在某队列中执行完毕，则它原地出局。
  - 过程
    - 如果一个作业很短，例如一个响应式用户操作，那么它进入队列1后，容易在时间片内执行完。而且由于在队列1中，大家的时间片都很短，所以并不需要等待很长时间。
    - 如果一个长作业来了，那么它进入队列1显然跑不完，就进入队列2，用完队列2的时间片再进入队列3，....。
      - 可见，就算一个作业很长，但是它也会第一时间得到响应，因为第1级队列很快。
      - 这个作业一定能执行完，因为它总是可以利用$1，2，3，...,i-1$各队列都是空时，排到它了取执行。如果这个作业执行完了，那么它一定是队列1上执行一点点，队列2上执行2倍时间的任务，队列3上执行4倍时间的任务，以此类推。他是一个渐进的过程。
  - 好处（来自Wikipedia）
    - 为什么称为`响应`队列？因为不管什么类型的作业，都保证了其`响应`时间非常短（<=第1级队列的排队时间）
    - 长作业也不会饥饿
    - Give preference to short jobs.
    - Give preference to [I/O bound](https://en.wikipedia.org/wiki/I/O_bound) processes.（因为只要去IO了，回来又到队列1了）
    - Separate processes into categories based on their need for the processor.

#### 临界区

> 注意，临界区是访问互斥资源的**那段代码**。并不是资源！

#### 进程同步的概念

- 同步是异步的反义词。之前对异步的解释是：多道程序下，指令执行的先后顺序是不可预期的。现在我们要让他可预期。也就是同步。
- **对临界区的访问**，要做到：
  - 空闲让进，忙则等待
  - **有限等待（红绿灯不能一直是红灯）**
  - **让权等待**（**当进程在等待进入时，应进入阻塞，让出核心或线程**）
- 实现临界区互斥的基本方法
  - 软件法
    - 4个算法
  - 硬件法
    - 关中断法（因为当且仅当出现中断，才会进行进程调度与切换）
      - 缺点：关中断的权利给了用户，不安全；且限制了多道程序的能力，降低效率。
    - TestAndSet、Swap法（两个原子操作，由函数给出描述，**但实际上由硬件实现，不可能被打断（因为根本不属于进程）**）
    - 硬件法的缺点
      - **不能实现让权等待。**（因为是使用while()的方式去等待，所以CPU一直在空转）
  - 信号量法（**P、V操作也是原子性的**。）
    - 数值型信号量
      - 一个共享的int型数据。while(sema<=0);
      - 不能实现**让权等待**。
    - 记录型信号量
      - 可以实现让权等待：即阻塞-唤醒型信号量。
      - 每个信号量都有一个**链表**，里面是所有等待该信号量的进程。新来一个P操作，就放入链表；空出来一个资源，就从链表取。
    - 信号量常用于**前驱图**问题、6个经典同步问题。
    - 信号量使用需要注意：**先同步，后互斥。（否则就会hold-and-wait**，也就是有死锁的可能性）

#### 经典同步问题

- 生产者消费者问题

  - 信号量
    - mutex：用于互斥访问缓冲区，所以=1
    - full：缓冲区中的元素个数，所以=0
    - empty：缓冲区中的空位个数，所以=n
  - 生产者
    - P(empty)：`申请`一个空位
    - P(mutex)，写，V(mutex)：互斥访问缓冲区
    - V(full)：`提供`一个元素
  - 消费者：
    - P(full)：`申请`一个元素
    - P(mutex)，读，V(mutex)：互斥访问缓冲区
    - V(empty)：`提供`一个空位

- 读者写者问题

  - 数据

    - counter：表示当前有多少个读者在读

  - 信号量

    - mutex：互斥访问counter，所以=1
    - rw：读者写者之间的互斥，保证同一时间内要么是读者在操作，要么是写者在操作。所以=1
    - w：防止写者饥饿。读者每次进入也得P(w)，成功进入就V(w)，当写者来了，P(w)；但是写者得写完了才会V(w)。于是，如果写者来了，当写者来之前最后一个读者进入后，写者就把读者封锁了。后面来的读者只能等待。因为是封锁，所以=1.
      - 注意，虽然能防止写者饥饿，但这**不属于写者优先**。假设很多读者和一个写者几乎同时来，但是写者还是慢了半拍，那么写者也不会排到读者前面。所以这种方式只是**防止了饥饿**。

  - 读者

    - P(w)：如果写者来了，w就到0了。所以如果写者在等待，读者就被封锁。（防止写者饥饿）
    - P(mutex)：对计数器互斥
    - if(counter==0)P(rw)：如果是第一个读者，就封锁写者（实现读写者之间的互斥）
    - counter++：统计读者数量
    - V(mutex)：对计数器互斥
    - V(w)：已经成功进入

    

    - reading.....

      

    - P(mutex)：对计数器互斥

    - counter--：统计读者数量

    - if(counter==0)V(rw)：如果是最后一个读者，撤销封锁（实现读写者之间的互斥）

    - V(mutex)：对计数器互斥

  - 写者

    - P(w)：封锁读者，防止自己饥饿
    - P(rw)：读写者互斥

    

    - write.....

    

    - V(rw)：读写者互斥
    - V(w)：撤销封锁

- 哲学家就餐问题

  - 如果哲学家只是简单地申请左右手的筷子，假设有5个哲学家，于是给筷子编号1，2，3，4，5.那么如果这些哲学家同时伸出左手，那么5，1，2，3，4号筷子依次被占用，当他们伸出右手，每个人都发现无筷可拿。这是死锁的一种情况。其他的拿取顺序也会导致类似的死锁。
  - 避免死锁：
    - 限制**同时**饥饿哲学家**数量**：如果n个哲学家，可以限制**最多有k个哲学家同时感到饥饿，k可以取1到n-1.**
    - 限制筷子抓取**顺序**：也可以让奇数哲学家先拿右手边，偶数哲学家先拿左手边。
  - 信号量：
    - hungry：当前剩余可允许同时感到饥饿的人数，可取1到n-1
    - chopsticks[n]：n支筷子，各自是一个初值1的信号量
  - 哲学家 $i$ ：
    - P(hungry)：申请感到饥饿
    - P(chopsticks[i])  P(chopsticks[(i+1)%5])：分别申请左右手的筷子
    - 干饭
    - V(hungry)：不再感到饥饿
    - V(chopsticks[i])  P(chopsticks[(i+1)%5])：分别放下左右手的筷子
    - 思考

- 抽烟者问题

  - 信号量
    - offer[3]：三种材料组合，各自对应一种信号量，初始值0
    - empty：桌子是否为空（相当于大小为1的缓冲区），所以初始值1
  - 生产者
    - P(empty)：等待桌子为空
    - 产生一个数字 $i$ ，然后V(i)
  - 抽烟者 $i$ ：
    - P(offer[i])：等待自己的材料
    - 抽烟
    - V(empty)：通知生产者

- 商品入库问题

  - 保证A数量-B数量<M，且B数量-A数量<N。

  - 信号量：

    - sa：A和B的数量差
    - sb：B和A的数量差
    - mutex：每次只能有一个商品入库

  - 以A商品入库为例：

    - V(sa)：A来了，A-B应当减小

    - P(mutex)：先同步，后互斥

    - 入库

    - V(mutex)

    - P(sb)：A来了，B-A应当增大

      

#### 可重入代码（纯代码）

- 即执行过程中不会被更改的代码。也就是说多次执行，不同进程去执行，其**逻辑**都是一样的。

#### 管程

- 对一个特定的数据结构进行封装，在其基础上提供对他的互斥访问、进程同步的方法。这样就可以避免在各个地方分散调用PV而导致不易管理的问题。
  - 即：给临界资源套壳，把互斥情况下对他需要用到的各种操作都封装进来。
  - 例如在实验6的管程OneWay中，封装了arrive、pass、quit方法。可见，管程所封装的方法是较高级的对数据结构进行操作的方法。并不是简单的wait和signal了。
- 管程的组成
  - 封装在内的需要互斥同步的数据结构，这些数据结构是private的。
  - 给数据结构进行初始化的方法（例如构造函数`OneWay()`）
  - 对数据结构进行操作的方法（例如`arrive()`、`pass()`、`quit()`函数）
- 管程往往是编程语言实现、提供的，例如java中就有。但是实验的时候，C下使我们自己实现的。
- 同一时刻只允许一个进程调用（或者说是进入）管程。这在实验六中采用的是进来就P，出去就V的方式。类似于互斥锁。

#### 进程之间的制约关系

- 进程之间有两种制约关系：同步、互斥
  - 同步是指两个进程协同完成一个任务，他们之间的顺序必须严格确定
  - 互斥是指临界资源访问

#### 死锁的概念

- 多个进程对**不可抢占（也就是只能自己主动释放）**资源的竞争，导致**互相等待**对方**释放**资源才能推进（否则**永远等待**。如果只是等待时间长，不能算死锁）。这种情况只能通过**外力强行剥夺那些不可抢占资源**才能解开。
  - 如果资源是可抢占的，不可能引起死锁。因为互相等待的任意一方都可以**抢占对方占有的**资源。
- 常见死锁产生的情况
  - 互相等待对方占有的的资源（因为资源竞争的顺序不当），例如信号量使用顺序不当（此时互相等待对方发出信号）。

#### 死锁的条件

- 不可抢占的互斥资源
  - 于是，资源只能**一方占有**且只能**主动释放**
- hold-and-wait
  - 在等待其他资源，导致无法执行的时候仍然不释放自己手头的资源
- 循环等待（如果是多实例资源，小心环外搅局者）
  - 即“互相等待”的推广。考虑两个进程互相等待，会造成死锁；如果是很多进程，想要造成死锁，类比哲学家就餐，也就是1等2，2等3，3等4，4又等1，于是谁也不会释放手头的资源，却又在等待其他人手里的资源。
  - 但是需要注意，这个等待的资源必须是**只被这个环上的下一个进程所持有的**。如果同时还有不属于这个环的进程持有，那么这个死锁在那个不属于这个环的进程释放资源后，可能就会**被打破**。**这种不属于循环等待**。也就无死锁。（**永远等待**才叫死锁。如果只是等待时间长，不能算死锁）
  - 但是如果这些资源都是单实例资源，那么不可能存在如上所述的“环外搅局者”。因为这个资源只有一份，只能是环上的进程所持有。这种情况，只要成环，就符合循环等待的定义了。

> 所以，如果一些进程是以**hold-and-wait**的方式**互相（即资源分配图成环）**等待**不可抢占的互斥资源**的，则死锁了。
>
> （一定要注意循环等待的定义。只要存在环外搅局者，就不能叫循环等待，也就不是死锁了。）

> 因此，在**环上的资源都是**单实例资源的情况下，资源分配图是有环图是死锁的充要条件；但是在多实例资源下，其只是必要条件。

#### 死锁处理三方法

- 死锁预防
  - 在运行**前**，设置限制条件，打破死锁的几个条件
- 死锁避免
  - 在运行**过程中**，避免进入不安全状态（寻找可能的资源分配安全顺序）
- 死锁检测与消除
  - 不加以任何干预。只是**定期**对死锁进行**探测**。如果发生了死锁需要能探测到，并且能解开它。
  - Windows系统采用这种方法，而且解开死锁的方式是重启电脑。

#### 死锁预防和死锁避免的区别

- 前者是在运行环境下给出各种限制；后者是发现将要进入不安全状态了才会限制。
- 很明显，前者是死锁避免的超集，导致限制条件**过于保姆**（就算是资源空闲了，我也不分配它），于是会对系统效率有非常显著的影响。
- 后者虽然效率高，但是由于在很多情况下很难探测不安全状态（因为无法预测将来的资源请求），所以实用性不高。

#### 死锁预防

- 破坏互斥条件（难以实施）
  - 不可能。之所以要互斥是有原因的。
- 破坏不剥夺条件
  - 只能是易于恢复现场的资源，例如CPU。
  - 打印机显然不能剥夺
- 破坏hold-and-wait：**资源预分配策略**
  - 当且仅当进程把需要的资源一次性都申请到了，它才能开始运行，否则只能一直等待下去。
  - 如果有的资源就算是只用1us，那也得一直占着。显然效率非常低。
  - 而且假设一个进程需要系统内所有类型的资源，它就饥饿了。因为等到一个时刻，系统所有资源都没人用，几乎不可能。
- 破坏循环等待（难以实施）：**资源顺序分配策略**
  - 编号法

#### 死锁避免

- 安全状态
  - 如果能找出一个安全序列（一个安全的资源分配序列），那当前就是安全状态。
  - 如果当前是不安全状态，则系统可能发生死锁（但不是一定发生死锁，因为假设其他进程能释放这种资源就可能打破死锁）
  - 死锁避免就是避免进入不安全状态。
- 作用
  - 死锁避免充当了一个资源管理员的角色。进程提出资源分配请求，死锁避免算法就检查（进行假分配），假设本次分配后，整体的局面是如何的，然后从这个局面里头寻找安全序列，如果找不到就说明如果同意了本次请求，系统就会进入不安全状态，**于是拒绝此请求**。

#### 死锁检测：基于死锁定理

- 一个系统的资源分配图不能被**完全简化**（即所有的进程都执行完毕）**的充分必要条件是**发生了死锁。
- 因此，死锁检测是检测的资源分配图。

#### 死锁解除

- 资源剥夺法：强制剥夺资源
- 撤销进程法：强制终止死锁的进程
- 回退法：回退到之前的（当时未发生死锁的）还原点处。这里的还原势必要剥夺资源，但这里的剥夺是**自愿的**。

### 内存管理

#### 内存管理的基本内容

- 内存空间的分配
  - 具体内存的分配由OS来做，于是编程时不需要像汇编那样去手动制定内存单元地址了。
- 地址转换
  - 将逻辑地址（例如C++的指针的值）转换成物理地址
- 内存空间的扩充
  - 虚存
- 保护
  - 保证各进程的内存空间互不干扰

#### 程序的链接

- 编译时静态链接
  - 在编译形成可执行文件时就连接上库文件
- 装入时动态链接
  - 把程序**装入内存时**，才链接
- **运行时**动态链接
  - 程序**运行到**需要该模块时，才把它装入内存并链接
  - 程序刚装入时是几乎没有链接的。这个和装入时动态链接的区别在于后者是一链接就全连接上了，**更占用内存**空间。

#### 程序的装入

- 绝对装入
  - 这种程序就像汇编一样，里面的地址给出的是实打实的物理地址，或者是符号地址，经汇编器转换为物理地址。在装入时，就是原封不动放入内存即可！
  - 这样的方式一般只能支持**单道程序**。你不能预测下一个装进来的程序会不会覆盖掉原来的那个。
- 静态重定位装入（又称重定位装入，硬性修改指令中的地址实现）
  - 程序中的地址使用了虚拟地址。**在装入时**，把这些虚拟地址**全都转换（采用原地替换的方式）（因为是直接替换，所以是静态的）**成物理地址。
  - 这种装入只是让编程人员方便了，且支持了多道程序（因为OS可以为不同的程序分配内存空间了），但是由于还是**硬性替换**，在装入时直接**定死了内存空间的范围**，所以程序内存空间**无法扩充与浮动**。
  - **必须一次性被装入**。因此如果要运行程序，**内存可用容量必须>=所需空间。**
  - 程序装入后，在运行时就没什么事了，一切都和绝对装入没有区别。而下面要说的动态重定位则是在运行时做文章。
- 动态重定位装入（又称运行时装入，运行时解释地址实现）
  - 程序中的地址使用了虚拟地址。但是在装入时，**只装入当前运行必要的部分**，且就算装入了也**不进行物理地址转换**。
  - 物理地址转换在当**需要转换时才进行转换（而且并不去替换原来的指令）**，例如当前要仿存，那么指令给出虚拟地址（即相对地址），经过和重定位寄存器（相当于基址寄存器）加和，得以正确访存。
  - 因为装入时只装入一小部分，所以不能保证程序是连续的。也就是程序会存在非连续空间中。而且由于重定位寄存器的存在，使程序分散存储成为可能。
  - 因为地址变换并不真正改变指令本身，而是在访存时**才现去解释他**，所以**支持**程序的**浮动**，**支持内存动态申请**。而且因为一开始只装入一点，**所以就算没有充足的内存也可以运行这个程序**。

#### 内存的保护

- 方法1（用于固定分配）：CPU中的上下限寄存器，保存了程序所在内存空间的**物理地址**上、下限。访存时比较即可。
- 方法2（用于固定分配、固定分区连续分配、可变分区连续分配）：Base和Limit寄存器。其中Base存放基址（物理地址），Limit存放空间长度（逻辑地址）；每次访存时，先用逻辑地址和Limit做比较，如果没有超过Limit，再和Base相加，得到物理地址。

#### 内存的扩充

- 覆盖
  - 内存分为固定区和覆盖区。固定区是安全的，程序可以在里面常驻；覆盖区是不安全的，会在运行时（Runtime）经常进行内容覆盖。
  - 例子：OS肯定放在固定区；假如来一个大程序，那么他的主函数应该在固定区，它的各个不经常用到的或周期性用到的函数在外存中存放。当执行到需要调用那个函数时，把那段函数代码从外存读到覆盖区中进行覆盖，于是就能执行他了。当执行下一个函数，类似。
  - 好处：可以运行比内存总量大得多的程序。但是如果某个模块过大，大于内存总量，仍然是无法执行的。
- 交换
  - 交换即中程调度。
- 二者的区别与联系
  - 注意，交换是不同进程之间的，而覆盖一般是统一进程的不同代码模块之间的。二者都是用于“扩充”内存的。
  - 现代的虚存往往使用交换。通过换入换出，可得到一个交换区+内存大小的逻辑内存空间。覆盖现在已经淘汰，

#### 连续内存分配方式——单一连续分配

- 把内存空间暴力地分成OS区和用户程序区，因此只支持单道程序。
- 优点：无外碎片。
- 缺点：显然存在内碎片。因为程序很难和这块区域正好一样大。

#### 连续内存分配方式——固定分区分配

- 把内存空间暴力地分成若干分区。这些分区可以是大小相等的，也可以是大小不同的。
- 维护一张分区表，其中的字段有base、limit、是否正在使用。
- 当需要分配时，查表即可。
- 优点：无外碎片。
- 缺点：显然存在内碎片。因为程序很难和这块区域正好一样大。

#### 连续内存分配方式——动态分区分配

- 一开始内存是空的，可以看做是一块大的连续区域。随着进程加入，这块区域逐渐被瓜分。**每加入一个新的进程（包括换入一个进程），原有的一个分区就被瓜分成两个分区，其中一个是程序使用的区域，另一个就是外碎片（空闲分区剩余部分）。**每结束一个进程（包括换出一个进程），就会合并其上下的空闲分区，使得2-3个分区**合并成同一个分区。**
- 外碎片可以通过紧凑算法解决，但是大多数硬件没有给出支持。
- 找空闲分区算法：
  - 首次适应：从上到下遍历这些分区，找到第一个放得下这个程序的。
    - 是效果最好的算法。
  - 最佳适应：找放得下这个程序的分区中最小的那个。
    - 糟糕的算法。
    - 每次“最佳”适应都会留下更小的外碎片，而且越“佳”就越小，导致内存利用率大幅下降。
  - 最坏适应：找放得下这个程序的分区中最大的那个。
    - 糟糕的算法。
    - 虽然瓜分后产生的外碎片比较大，有重新利用的可能，**但是这种算法就像是`斗地主`的时候把炸弹拆开了用一样啥比**，破坏了能装更大程序进来的可能。这导致内存中存在的最大的分区的体积越来越小。
  - 临近适应：首次适应。只不过从上次找到了的地方开始找，而不是从头开始找。
- 优点
  - 灵活，无内碎片
- 缺点
  - 有很多外碎片
- （注意，这里产生的碎片类型和前两种方式反过来了）

#### Introduction To 非连续内存分配方式

- 非连续分区的好处：在连续分区中，装下一个程序的关键在于有大于等于其大小的**连续空间**。但是非连续分区**只要求剩余空间总大小**大于等于其大小即可。
- 分段和分页的区别：分区大小是否是固定的。